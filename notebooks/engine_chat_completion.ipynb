{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2b6b7d0-dd86-4275-be30-c83df4b925ea",
   "metadata": {},
   "source": [
    "# Direct Engine Access\n",
    "\n",
    "This notebook is about playing around to create an entry point where the user manages their state themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcd8597-9429-4cd3-8259-0c82139fb210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import guidance\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "gguf = hf_hub_download(\n",
    "    repo_id=\"microsoft/Phi-3-mini-4k-instruct-gguf\",\n",
    "    filename=\"Phi-3-mini-4k-instruct-q4.gguf\",\n",
    ")\n",
    "\n",
    "# Define the model we will use\n",
    "# lm = guidance.models.LlamaCpp(gguf, n_gpu_layers=-1)\n",
    "lm = guidance.models.Transformers(\"microsoft/Phi-3-mini-4k-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0a9cbc-ae9d-4727-8c31-28ff7e7daee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\" : \"user\",\n",
    "        \"content\": \"Tell me about yourself\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799135a0-5221-4182-91e0-98d335bb74c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = \"\"\"%llguidance {}\n",
    "\n",
    "start: \"My name is \" name \" and my motto is \" motto\n",
    "name[capture=\"name\", temperature=1.0]: NAME\n",
    "motto[capture=\"motto\", temperature=0.7]: MOTTO\n",
    "NAME: \"Phi-3, the Magnificent\"\n",
    "    | \"Phi-3, the Terrible\"\n",
    "    | \"Phi-3, the Great\"\n",
    "    | \"Phi-3, the Conqueror\"\n",
    "MOTTO: \"Look on my works ye mighty, and despair\"\n",
    "    | \"Apres moi, le deluge\"\n",
    "    | \"Alea iacta est\"\n",
    "    | \"Apres moi, le table\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2249736-7a9f-4de9-8a84-fac271e37e4b",
   "metadata": {},
   "source": [
    "Grab the `engine` object out of the Model. Note that this is only going to work for local models (basically, Models contain Interpreters, but only the local Interpreters then contain an engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2ef1fe-eb9f-4412-9941-d74de7c76301",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = lm._interpreter.engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b9945d-6dcc-4f18-8440-4308cb3011cd",
   "metadata": {},
   "source": [
    "Call the new API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec01b076-42ef-46f1-aaf7-f009ae68c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.chat_completion(messages, grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6d698c-47a4-48e7-ae36-db4bf4e8cdf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
