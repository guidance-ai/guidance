{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "882fb634-0efc-42bf-8cc5-79d6a7312e26",
   "metadata": {},
   "source": [
    "# Using OpenAI models from Azure AI\n",
    "\n",
    "You can also use an OpenAI model deployed into Azure AI.\n",
    "For this, you will provide a few pieces of information from the Azure AI playground:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61665201-12a8-4588-bb54-801a367c7535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "# This is the name of the model deployed, such as 'gpt-4' or 'gpt-35-turbo\n",
    "model = 'gpt-4'\n",
    "# This is the deployment URL, as provided in the Azure AI playground ('view code'):\n",
    "azure_endpoint = os.getenv(\"AZUREAI_ENDPOINT\", \"Please set the endpoint\")\n",
    "# The environment variable should be set to the API key from the Azure AI playground:\n",
    "api_key=os.getenv(\"AZUREAI_KEY\", \"Please set API key\")\n",
    "# Alternatively, we can use Entra authentication\n",
    "token_provider = get_bearer_token_provider(\n",
    "    DefaultAzureCredential(),\n",
    "    \"https://cognitiveservices.azure.com/.default\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3203ea1-00b7-4cc6-9b92-5167d453a790",
   "metadata": {},
   "source": [
    "We can now construct the `guidance` model object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29187b26-93bc-459f-bb9d-ac22feef473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from guidance import models, gen\n",
    "\n",
    "azureai_model = models.AzureOpenAIChat(\n",
    "    model=model,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    # For authentication, use either\n",
    "    azure_ad_token_provider=token_provider,\n",
    "    # or\n",
    "    # api_key=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f95b1ef-402a-4b96-b0b0-a0bd007d582b",
   "metadata": {},
   "source": [
    "We can use the model as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b03a844-0c4c-446e-91ed-408494114d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from guidance import system, user, assistant\n",
    "\n",
    "with system():\n",
    "    lm = azureai_model + \"You are a helpful assistant.\"\n",
    "    \n",
    "with user():\n",
    "    lm += \"What is the meaning of life?\"\n",
    "\n",
    "with assistant():\n",
    "    lm += gen(\"response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa274c5-01c6-46f9-a024-b8b44e16ce2c",
   "metadata": {},
   "source": [
    "This works with the multistep example as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c9d8ff-99e2-4806-8ff5-7f57491d7361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import guidance\n",
    "# you can create and guide multi-turn conversations by using a series of role tags\n",
    "@guidance\n",
    "def experts(lm, query):\n",
    "    with system():\n",
    "        lm += \"You are a helpful assistant.\"\n",
    "\n",
    "    with user():\n",
    "        lm += f\"\"\"\\\n",
    "        I want a response to the following question:\n",
    "        {query}\n",
    "        Who are 3 world-class experts (past or present) who would be great at answering this?\n",
    "        Please don't answer the question or comment on it yet.\"\"\"\n",
    "\n",
    "    with assistant():\n",
    "        lm += gen(name='experts', max_tokens=300)\n",
    "    \n",
    "    with user():\n",
    "        lm += f\"\"\"\\\n",
    "        Great, now please answer the question as if these experts had collaborated in writing a joint anonymous answer.\n",
    "        In other words, their identity is not revealed, nor is the fact that there is a panel of experts answering the question.\n",
    "        If the experts would disagree, just present their different positions as alternatives in the answer itself\n",
    "        (e.g. 'some might argue... others might argue...').\n",
    "        Please start your answer with ANSWER:\"\"\"\n",
    "    \n",
    "    with assistant():\n",
    "        lm += gen(name='answer', max_tokens=500)\n",
    "\n",
    "    return lm\n",
    "                   \n",
    "azureai_model + experts(query='What is the meaning of life?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38ed2e8-ac20-4803-ae91-cc0fcde4248f",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
