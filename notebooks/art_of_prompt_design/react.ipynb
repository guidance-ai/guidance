{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`The Art of Prompt Design`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReAct Design Pattern\n",
    "\n",
    "*Authors: @Sam1320, @slundberg*\n",
    "\n",
    "The ReAct prompting strategy (by <a href=\"https://arxiv.org/abs/2210.03629\">Yao et al.</a>) consists of prompting a language model to generate explicit reasoning traces that contain an \"action\" step. The action step selects actions to execute in order to gain more information. ReAct can be viewed as a specific form of chain of thought combined with tool use. To execute the ReAct pattern we just need to follow the standard tool use paradigm of executing the selected actions and injecting the result (aka. Observation) back into the prompt and repeating the process until a final answer is found. This \n",
    "\n",
    "This notebook shows two different ways to leverage `guidance` to implement this pattern:\n",
    "\n",
    "1. <a href=\"#gen_with_tools\">Using the `tools` API of the `gen` function.</a>\n",
    "2. <a href=\"#raw_function\">Using a ReAct-specific stateful guidance function.</a>\n",
    "<!-- 3. Adapting ReAct to use the function calling APIs using by remote model services like Vertex AI and OpenAI. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First let's import the necessary modules and load the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "import guidance\n",
    "from guidance import models, gen, select\n",
    "\n",
    "repo_id = \"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\"\n",
    "filename = \"mistral-7b-instruct-v0.2.Q8_0.gguf\"\n",
    "model_kwargs = {\"verbose\": True, \"n_gpu_layers\": -1, \"n_ctx\": 4096}\n",
    "\n",
    "downloaded_file = hf_hub_download(repo_id=repo_id, filename=filename)\n",
    "mistral7 = guidance.models.LlamaCpp(downloaded_file, **model_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the same prompt for both approaches so let's define it here. We will use two simple functions `sqrt` and `age` (returns age of a famous person) as tools to demonstrate the pattern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Answer the following questions as best you can. You have access only to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought 1: you should always think about what to do\n",
    "Action 1: the action to take, has to be one of {tool_names}\n",
    "Observation 1: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought N: I now know the final answer.\n",
    "Final Answer: the final answer to the original input question.\n",
    "Done.\n",
    "\n",
    "Example:\n",
    "Question: What is the square root of the age of Brad Pitt?\n",
    "Thought 1: I should find out how old Brad Pitt is.\n",
    "Action 1: age(Brad Pitt)\n",
    "Observation 1: 56\n",
    "Thought 2: I should find the square root of 56.\n",
    "Action 2: sqrt(56)\n",
    "Observation 2: 7.48\n",
    "Thought 3: I now know the final answer.\n",
    "Final Answer: 7.48\n",
    "Done.\n",
    "\n",
    "Question: {query}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing ReAct using the `tools` API of the `gen` function<a id=\"gen_with_tools\"></a>\n",
    "We can define tools that can be used and then pass them as arguments to `gen`. Guidance will identify when the model generates something that matches the grammar of a tool call, execute it and then resume generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first define our set of functions that can be used as tools. The output of these functions is inserted back into the program right after the call to the function. For this reason, in order to match the pattern of the prompt above, we'll add \"Observation N\" before the output of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from guidance import regex\n",
    "\n",
    "ages_db = {\n",
    "    \"Leonardo DiCaprio\": 49,\n",
    "    \"Brad Pitt\": 59\n",
    "}\n",
    "\n",
    "@guidance\n",
    "def sqrt(lm, number):\n",
    "    lm += f'\\nObservation {regex(r\"[0-9]+\")}: ' + f'{math.sqrt(float(number))}\\n'\n",
    "    return lm\n",
    "\n",
    "@guidance\n",
    "def log(lm, number):\n",
    "    lm += f'\\nObservation {regex(r\"[0-9]+\")}: {math.log(float(number)):.4f}\\n'\n",
    "    return lm\n",
    "\n",
    "@guidance\n",
    "def age(lm, person):\n",
    "    lm += f'\\nObservation {regex(r\"[0-9]+\")}: {ages_db.get(person)}\\n'\n",
    "    return lm\n",
    "\n",
    "tools = {\n",
    "    \"sqrt\": \"Computes the square root of a number.\", \n",
    "    \"age\": \"Returns the age of a person.\", \n",
    "    \"log\": \"Computes the logarithm of a number.\"\n",
    "}\n",
    "tool_map = {\n",
    "    \"sqrt\": sqrt,\n",
    "    \"age\": age,\n",
    "    \"log\": log\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Program\n",
    "Now we can start generation just by adding the model and the prompt to `gen` and passing the tools as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the logarithm of Leonardo DiCaprio's age?\"\n",
    "prompt_with_query = prompt.format(tools=tools, tool_names=list(tools.keys()), query=query)\n",
    "lm = mistral7 + prompt_with_query + gen(max_tokens=200, tools=[sqrt, age, log], stop=\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing ReAct Directly Using Stateful Control <a id=\"raw_function\"></a>\n",
    "Instead of passing the tools as arguments to `gen` we can use stateful control to guide the execution of the program. This allows for more fine grained control. \n",
    "\n",
    "In this case we'll define a function that runs the ReAct loop. Note that now `select` constrains the model to select one of the available tools. Also, we don't need to add prefixes to the tools since all the context is finely controlled inside the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_map = {\n",
    "    \"sqrt\": lambda x: str(math.sqrt(float(x))),\n",
    "    \"age\": lambda x: str(ages_db.get(x)),\n",
    "    \"log\": lambda x: str(math.log(float(x)))\n",
    "}\n",
    "@guidance\n",
    "def react_prompt_example(lm, question, tools, max_rounds=10):\n",
    "    tool_names = list(tools.keys())\n",
    "    lm += prompt.format(tools=tools, tool_names=tool_names, query=question)\n",
    "    i = 1\n",
    "    while True:\n",
    "        lm += f'Thought {i}: ' + gen(name='thought', suffix='\\n')\n",
    "        if 'final answer' in lm['thought'] or i == max_rounds:\n",
    "            lm += 'Final Answer: ' + gen(name='answer', suffix='\\n')\n",
    "            break\n",
    "        lm += f'Act {i}: ' + select(tool_names, name='act') \n",
    "        lm += '(' + gen(name='arg', suffix=')') + '\\n'\n",
    "        if lm['act'] in tool_map:\n",
    "            lm += f'Observation {i}: ' + tool_map[lm['act']](lm['arg']) + '\\n'\n",
    "        i += 1\n",
    "    return lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = mistral7\n",
    "lm += react_prompt_example(\"What is the logarithm of Leonardo DiCaprio's age?\", tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can access the final answer which we stored in the program state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query) \n",
    "print(f\"Response: {lm['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 1px; opacity: 0.5; border: none; background: #cccccc;\">\n",
    "<div style=\"text-align: center; opacity: 0.5\">Have an idea for more helpful examples? Pull requests that add to this documentation notebook are encouraged!</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
