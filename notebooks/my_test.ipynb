{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import guidance\n",
    "import re\n",
    "import os\n",
    "\n",
    "# set Openai API key\n",
    "os.environ.setdefault(\"OPENAI_API_KEY\", \"sk-\")\n",
    "\n",
    "model = guidance.llms.OpenAI(\"gpt-3.5-turbo\", chat_mode=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the chain of thought\n",
    "\n",
    "chain_of_thought = guidance('''\n",
    "{{#system~}}\n",
    "You are a knowledgeable and efficient assistant.\n",
    "{{~/system}}\n",
    "\n",
    "{{#user~}}\n",
    "Please analyze the following question:\n",
    "{{query}}\n",
    "Identify the exact topic and user intent in one sentence.\n",
    "{{~/user}}\n",
    "\n",
    "{{#assistant~}}\n",
    "{{gen 'topic_intent' temperature=0 max_tokens=50}}\n",
    "{{~/assistant}}\n",
    "\n",
    "{{#user~}}\n",
    "Based on the topic and intent, what information is required to adequately answer this question?\n",
    "{{~/user}}\n",
    "\n",
    "{{#assistant~}}\n",
    "{{gen 'info_requirements' temperature=0 max_tokens=100}}\n",
    "{{~/assistant}}\n",
    "\n",
    "{{#user~}}\n",
    "Here is a text source that might contain the answer:\n",
    "{{knowledge}}\n",
    "Analyze if this text contains the necessary information and respond with 'Yes' or 'No'.\n",
    "{{~/user}}\n",
    "\n",
    "{{#assistant~}}\n",
    "{{gen 'text_analysis_conclusion' temperature=0 max_tokens=50}}\n",
    "{{~/assistant}}\n",
    "\n",
    "{{#if (contains text_analysis_conclusion 'Yes')}}\n",
    "{{#user~}}\n",
    "This is some knowledge:\n",
    "{{knowledge}}\n",
    "Generate a comprehensive answer based on the knowledge provided.\n",
    "{{~/user}}                 \n",
    "{{#assistant~}}\n",
    "{{gen 'final_answer_based_on_knowledge' temperature=0 max_tokens=300}}\n",
    "{{~/assistant}}\n",
    "\n",
    "{{else}}\n",
    "{{#user~}}\n",
    "\n",
    "Generate a question that would elicit the missing information.\n",
    "{{~/user}}\n",
    "{{#assistant~}}                           \n",
    "{{gen 'question_for_missing_info' temperature=0 max_tokens=300}}\n",
    "{{~/assistant}}\n",
    "{{/if}}\n",
    "''', llm=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some questions and knowledge sources\n",
    "\n",
    "questions = [\"What are the health benefits of regular exercise?\",\n",
    "             \"How do changes in ocean temperature affect marine life?\",\n",
    "             \"What are the implications of AI in healthcare?\"\n",
    "]\n",
    "\n",
    "knowledge = [\"Regular exercise contributes to improved cardiovascular health, enhanced muscle strength, better mood regulation due to increased endorphin release, and aids in maintaining a healthy weight. It also reduces the risk of chronic diseases such as type 2 diabetes, heart disease, and certain types of cancer.\",\n",
    "            \"The ocean is a vast and complex ecosystem. It provides habitat for countless species and plays a critical role in Earth's climate. Ocean currents are responsible for distributing heat around the globe, and the ocean absorbs large amounts of CO2 from the atmosphere.\",\n",
    "             \"Artificial Intelligence (AI) is rapidly evolving and being integrated into various sectors, including healthcare. In healthcare, AI is used for data analysis, patient care, and diagnostic processes. While it offers efficiency and accuracy, concerns about data privacy and the ethical implications of AI in decision-making remain topics of discussion.\"\n",
    "             ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the output\n",
    "\n",
    "for i, (question, knowledge) in enumerate(zip(questions, knowledge)):\n",
    "    output = chain_of_thought(query=question, knowledge=knowledge)\n",
    "\n",
    "    print(output)\n",
    "\n",
    "    print(f'--------{i}----------')\n",
    "    print(\"Question: \", question)\n",
    "    print(\"Intent: \" + output['topic_intent'])\n",
    "    print(\"Info Requirements: \" + output['info_requirements'])\n",
    "    print(\"Analysis: \" + output['text_analysis_conclusion'])\n",
    "    \n",
    "    # Check if the final answer is based on the knowledge or a generated question for missing info\n",
    "    if 'final_answer_based_on_knowledge' in output:\n",
    "        print(\"Final Answer: \" + output['final_answer_based_on_knowledge'])\n",
    "    elif 'question_for_missing_info' in output:\n",
    "        print(\"Question for Missing Info: \" + output['question_for_missing_info'])\n",
    "    \n",
    "    print('-------------------')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
