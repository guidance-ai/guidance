{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2b6b7d0-dd86-4275-be30-c83df4b925ea",
   "metadata": {},
   "source": [
    "# Direct Engine Access\n",
    "\n",
    "This notebook is about playing around to create an entry point where the user manages their state themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcd8597-9429-4cd3-8259-0c82139fb210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import guidance\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "gguf = hf_hub_download(\n",
    "    repo_id=\"microsoft/Phi-3-mini-4k-instruct-gguf\",\n",
    "    filename=\"Phi-3-mini-4k-instruct-q4.gguf\",\n",
    ")\n",
    "\n",
    "# Define the model we will use\n",
    "# lm = guidance.models.LlamaCpp(gguf, n_gpu_layers=-1)\n",
    "lm = guidance.models.Transformers(\"microsoft/Phi-3-mini-4k-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0a9cbc-ae9d-4727-8c31-28ff7e7daee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\" : \"user\",\n",
    "        \"content\": \"What is your name?\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799135a0-5221-4182-91e0-98d335bb74c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = \"\"\"%llguidance {}\n",
    "\n",
    "start: START\n",
    "START: \"Aa\"{2,} \"Bb\"{1,3}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2249736-7a9f-4de9-8a84-fac271e37e4b",
   "metadata": {},
   "source": [
    "Grab the `engine` object out of the Model. Note that this is only going to work for local models (basically, Models contain Interpreters, but only the local Interpreters then contain an engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2ef1fe-eb9f-4412-9941-d74de7c76301",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = lm._interpreter.engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b9945d-6dcc-4f18-8440-4308cb3011cd",
   "metadata": {},
   "source": [
    "There should be a chat template available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c658a71c-66a6-4d59-89a1-70fe63e0f00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = engine.get_chat_template().template_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5631ea-a909-4ba1-a4f3-eb845c99d9f7",
   "metadata": {},
   "source": [
    "Render the template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8504e7-9f40-4727-a0fe-d94f3241de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Environment, BaseLoader\n",
    "\n",
    "rtemplate = Environment(loader=BaseLoader).from_string(chat_template)\n",
    "rendered_prompt = rtemplate.render(messages=messages, eos_token=engine.tokenizer.eos_token.decode(\"utf-8\"))\n",
    "rendered_prompt += engine.get_chat_template().get_role_start(\"assistant\")\n",
    "\n",
    "print(\"Rendered Prompt:\\n\", rendered_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd8dc6c-c6c7-48bf-9819-dd9c54bad1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = guidance.models._engine.EngineState()\n",
    "\n",
    "state.prompt = rendered_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c1e1d5-0c67-4868-bec9-9655c32ee43e",
   "metadata": {},
   "source": [
    "Run the grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fe89ca-84b0-4382-9a1d-931a246900e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_response = bytearray()\n",
    "for nxt in engine(state, grammar):\n",
    "    nxt_tokens = [x.token_id for x in nxt.tokens]\n",
    "    nxt_bytes = engine.tokenizer.decode(nxt_tokens)\n",
    "    full_response += nxt_bytes\n",
    "print(full_response.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6d698c-47a4-48e7-ae36-db4bf4e8cdf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
