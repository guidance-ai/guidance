{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "213de727",
   "metadata": {},
   "source": [
    "# Defining Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cc9c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from guidance import Tool\n",
    "from typing import Literal\n",
    "import random\n",
    "\n",
    "def get_weather(city: str, unit: Literal[\"celsius\", \"fahrenheit\"] = \"celsius\") -> str:\n",
    "    \"\"\"\n",
    "    Get the current weather for a given city.\n",
    "    \n",
    "    Args:\n",
    "        city (str): The name of the city to get the weather for.\n",
    "        unit (Literal[\"celsius\", \"fahrenheit\"]): The unit of temperature to return.\n",
    "    \n",
    "    Returns:\n",
    "        str: A string describing the current weather in the specified city.\n",
    "    \"\"\"\n",
    "    temp = random.randint(-10, 35)\n",
    "    if unit == \"fahrenheit\":\n",
    "        temp = temp * 9/5 + 32\n",
    "    return f\"The current temperature in {city} is {temp} degrees {unit}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea02b0f6",
   "metadata": {},
   "source": [
    "A `Tool` consist of:\n",
    "1. A `callable` that should be invoked when the tool is called\n",
    "2. A `name` that uniquely identifies the callable\n",
    "3. A `description` that indicates the usage of the callable\n",
    "4. A `schema` that specifies the types of the callable's arguments, along with any metadata such as examples, default values, etc.\n",
    "\n",
    "Note that the `schema` currently must be a `pydantic.BaseModel`, but direct support for JSON schemas is incoming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83894ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, ConfigDict\n",
    "\n",
    "class GetWeatherArgs(BaseModel):\n",
    "    city: str = Field(..., description=\"The name of the city to get the weather for.\")\n",
    "    unit: Literal[\"celsius\", \"fahrenheit\"] = Field(\"celsius\", description=\"The unit of temperature to return.\")\n",
    "\n",
    "    model_config = ConfigDict(\n",
    "        extra=\"forbid\", # Disallow extra fields -- required for OpenAI\n",
    "    )\n",
    "\n",
    "tool = Tool(\n",
    "    callable=get_weather,\n",
    "    name=\"get_weather\",\n",
    "    description=\"Get the current weather for a given city.\",\n",
    "    schema=GetWeatherArgs\n",
    ")\n",
    "\n",
    "print(f\"\"\"\\\n",
    "Tool name:\n",
    "{tool.name}\n",
    "\n",
    "Tool description:\n",
    "{tool.description}\n",
    "\n",
    "Tool schema:\n",
    "{tool.schema.model_json_schema()}\\\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d8ae54",
   "metadata": {},
   "source": [
    "As an alternative to constructing a `Tool` manually, `guidance` can infer the tool's `name`, `description`, and `schema` from the callable's name, docstring, and signature annotations, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34db569",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = Tool.from_callable(get_weather)\n",
    "\n",
    "print(f\"\"\"\\\n",
    "Tool name:\n",
    "{tool.name}\n",
    "\n",
    "Tool description:\n",
    "{tool.description}\n",
    "\n",
    "Tool schema:\n",
    "{tool.schema.model_json_schema()}\\\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b78a7e1",
   "metadata": {},
   "source": [
    "# Calling Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefdfd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from guidance import gen, user, assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1063b48c",
   "metadata": {},
   "source": [
    "## Remote Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c68755",
   "metadata": {},
   "source": [
    "Most remote models have native support for tool-calling.\n",
    "\n",
    "With these models, you can simply pass a list of tools to `gen`.\n",
    "\n",
    "Behind the scenes, `guidance` automatically translates the `gen` to a call to the model provider's API, which in the case of OpenAI looks like:\n",
    "\n",
    "```python\n",
    "from openai import OpenAI\n",
    "client = OpenAI(...)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    messages=[...],\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": tool.name,\n",
    "                \"description\": tool.description,\n",
    "                \"parameters\": tool.schema.model_json_schema(),\n",
    "                \"strict\": True,\n",
    "            }\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "*Note*: you may pass a list of `callable` instead, and the `Tool`s will be automatically constructed for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfeb08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from guidance.models import OpenAI\n",
    "lm = OpenAI(\"gpt-4o-mini\")\n",
    "\n",
    "with user():\n",
    "    lm += \"What is the weather like in San Francisco?\"\n",
    "with assistant():\n",
    "    lm += gen(tools=[tool])\n",
    "with assistant():\n",
    "    lm += gen()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3b9ccf",
   "metadata": {},
   "source": [
    "You may notice that the tool call is wrapped in `<function={name}>...</function>` tags and the result is wrapped in `<function_result>..</function_result>` tags. This is purely for visualization purposes, as OpenAI uses a structured representation under the hood which we (somewhat arbitrarily) represent as a string above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862ca5dd",
   "metadata": {},
   "source": [
    "## Local Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed5e959",
   "metadata": {},
   "source": [
    "### The hard way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69dcdf4",
   "metadata": {},
   "source": [
    "Because local models do not have \"native\" support for tool calls, we have to provide a little more information. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2466d7",
   "metadata": {},
   "source": [
    "First, we prompt our model with an explanation of the tools that it has access to as well as the syntax we expect it to use. While `guidance` will guarantee that the model follows the specified syntax, it is no replacement for proper prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebefb8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from guidance.models import LlamaCpp\n",
    "from guidance import system\n",
    "from huggingface_hub import hf_hub_download\n",
    "from json import dumps\n",
    "\n",
    "model = LlamaCpp(\n",
    "    hf_hub_download(\n",
    "        repo_id=\"unsloth/Qwen3-0.6B-GGUF\",\n",
    "        filename=\"Qwen3-0.6B-BF16.gguf\",\n",
    "    ),\n",
    "    n_ctx=4096,\n",
    ")\n",
    "\n",
    "with system():\n",
    "    model += f\"\"\"\\\n",
    "# Tools\n",
    "\n",
    "You may call one or more functions to assist with the user query.\n",
    "\n",
    "You are provided with function signatures within <tools></tools> XML tags:\n",
    "<tools>\n",
    "{dumps({\"name\": tool.name, \"description\": tool.description, \"arguments\": tool.schema.model_json_schema()})}\n",
    "</tools>\n",
    "\n",
    "For each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\n",
    "<tool_call>\n",
    "{{\"name\": <function-name>, \"arguments\": <args-json-object>}}\n",
    "</tool_call>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a38477",
   "metadata": {},
   "outputs": [],
   "source": [
    "from guidance import lark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291fcbcb",
   "metadata": {},
   "source": [
    "https://github.com/guidance-ai/llguidance/blob/main/docs/syntax.md#tool-calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf92da13",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"name\": {\"type\": \"string\", \"const\": tool.name},\n",
    "        \"arguments\": tool.schema.model_json_schema(),\n",
    "    },\n",
    "    \"required\": [\"name\", \"arguments\"],\n",
    "    \"additionalProperties\": False\n",
    "}\n",
    "\n",
    "l = lark(f\"\"\"\\\n",
    "start: TEXT | tool_call\n",
    "tool_call: tool_call_trigger \"\\\\n\" tool_call_body \"\\\\n\" </tool_call>\n",
    "tool_call_trigger: TEXT <tool_call>\n",
    "tool_call_body[capture]: %json {dumps({\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"name\": {\"type\": \"string\", \"const\": tool.name},\n",
    "        \"arguments\": tool.schema.model_json_schema(),\n",
    "    },\n",
    "    \"required\": [\"name\", \"arguments\"],\n",
    "    \"additionalProperties\": False\n",
    "})}\n",
    "TEXT: /(.|\\\\n)*/\n",
    "\"\"\")\n",
    "\n",
    "tool_grammar = lark(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4459f358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from guidance import optional, special_token, json\n",
    "tool_grammar = gen() + optional(\n",
    "    special_token(\"<tool_call>\")\n",
    "    + json(\n",
    "        schema={\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"name\": {\"type\": \"string\", \"const\": tool.name},\n",
    "                \"arguments\": tool.schema.model_json_schema(),\n",
    "            },\n",
    "            \"required\": [\"name\", \"arguments\"],\n",
    "            \"additionalProperties\": False\n",
    "        },\n",
    "        name=\"tool_call\",\n",
    "    )\n",
    "    + special_token(\"</tool_call>\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963f857e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from guidance import special_token\n",
    "with user():\n",
    "    model += \"What is the weather like in San Francisco?\"\n",
    "with assistant():\n",
    "    model += special_token(\"<think>\") + gen(max_tokens=100) + special_token(\"</think>\")\n",
    "    model += tool_grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de15f2f",
   "metadata": {},
   "source": [
    "### The easy way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129678e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from guidance import ToolCallHandler\n",
    "\n",
    "class Qwen3ToolCallHandler(ToolCallHandler):\n",
    "    expr = re.compile(r\"<tool_call>\\n(?P<call>\\{(.|\\n)*\\})\\n</tool_call>\")\n",
    "\n",
    "    def trigger(self):\n",
    "        return \"<tool_call>\"\n",
    "\n",
    "    def begin(self, tool_name: str) -> str:\n",
    "        return \"<tool_call>\\n\"\n",
    "\n",
    "    def body(self, tool: Tool) -> GrammarNode:\n",
    "        return json(\n",
    "            schema={\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\"type\": \"string\", \"const\": tool.name},\n",
    "                    \"arguments\": tool.schema.model_json_schema(),\n",
    "                },\n",
    "                \"required\": [\"name\", \"arguments\"],\n",
    "                \"additionalProperties\": False,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def end(self) -> str:\n",
    "        return \"\\n</tool_call><|im_end|>\\n\"\n",
    "\n",
    "    def parse_tool_calls(self, text: str) -> list[RawToolCall]:\n",
    "        matches = self.expr.finditer(text)\n",
    "        tool_calls = []\n",
    "        for match in matches:\n",
    "            call_data = loads(match.group(\"call\"))\n",
    "            tool_calls.append(RawToolCall(name=call_data[\"name\"], args=call_data[\"arguments\"]))\n",
    "        return tool_calls\n",
    "\n",
    "    def format_return_value(self, value: Any) -> str:\n",
    "        return f\"<|im_start|>user\\n<tool_response>\\n{dumps(value)}\\n</tool_response>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce967c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lm = LlamaCpp(\n",
    "    hf_hub_download(\n",
    "        repo_id=\"unsloth/Qwen3-0.6B-GGUF\",\n",
    "        filename=\"Qwen3-0.6B-BF16.gguf\",\n",
    "    ),\n",
    "    n_ctx=4096,\n",
    "    tool_call_handler_cls=Qwen3ToolCallHandler\n",
    ")\n",
    "\n",
    "with system():\n",
    "    lm += f\"\"\"\\\n",
    "# Tools\n",
    "\n",
    "You may call one or more functions to assist with the user query.\n",
    "\n",
    "You are provided with function signatures within <tools></tools> XML tags:\n",
    "<tools>\n",
    "{dumps({\"name\": tool.name, \"description\": tool.description, \"arguments\": tool.schema.model_json_schema()})}\n",
    "</tools>\n",
    "\n",
    "For each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\n",
    "<tool_call>\n",
    "{{\"name\": <function-name>, \"arguments\": <args-json-object>}}\n",
    "</tool_call>\"\"\"\n",
    "with user():\n",
    "    lm += \"What is the weather like in San Francisco?\"\n",
    "with assistant():\n",
    "    lm += gen(tools=[tool])\n",
    "with assistant():\n",
    "    lm += gen()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guidance-ai (3.10.15)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
