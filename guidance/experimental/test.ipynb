{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from guidance import *\n",
    "from huggingface_hub import hf_hub_download\n",
    "model_path = hf_hub_download(\"lmstudio-community/Phi-3.1-mini-4k-instruct-GGUF\", \"Phi-3.1-mini-4k-instruct-IQ3_M.gguf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf50b682b7547e69f33d0e751158fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a289b0b8dbe4e3c9032e311412d9efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "StitchWidget(initial_height='auto', initial_width='100%', srcdoc='<!doctype html>\\n<html lang=\"en\">\\n<head>\\n …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to get per token stats: 0\n"
     ]
    }
   ],
   "source": [
    "model = models.Transformers(\"microsoft/Phi-3-mini-4k-instruct\", trust_remote_code=True, attn_implementation=\"eager\")\n",
    "# model = models.OpenAI(\"gpt-4o-mini\")\n",
    "# model = models.LlamaCpp(\"hf_hub://lmstudio-community/Phi-3.1-mini-4k-instruct-GGUF/Phi-3.1-mini-4k-instruct-IQ3_M.gguf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea540eb74575423085c6cb531e93f13c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "StitchWidget(initial_height='auto', initial_width='100%', srcdoc='<!doctype html>\\n<html lang=\"en\">\\n<head>\\n …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are not running the flash-attention implementation, expect numerical differences.\n",
      "gpustat is not installed, run `pip install gpustat` to collect GPU stats.\n",
      "Failed to get per token stats: 30\n"
     ]
    }
   ],
   "source": [
    "lm = model\n",
    "with system():\n",
    "    lm += \"Talk like a pirate!\"\n",
    "with user():\n",
    "    lm += \"Hello, model!\"\n",
    "with assistant():\n",
    "    lm += gen()\n",
    "with user():\n",
    "    lm += \"What is the capital of France?\"\n",
    "with assistant():\n",
    "    lm += gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image as PILImage\n",
    "# import requests\n",
    "# from io import BytesIO\n",
    "# from guidance.experimental.ast import ImageBlob\n",
    "\n",
    "# with user():\n",
    "#     lm += \"Can you describe the contents of this image?\"\n",
    "#     lm += ImageBlob(image=PILImage.open(BytesIO(requests.get(\"https://picsum.photos/300/200\").content)))\n",
    "# with assistant():\n",
    "#     lm += gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "Talk like a pirate!<|end|>\n",
      "<|user|>\n",
      "Hello, model!<|end|>\n",
      "<|assistant|>\n",
      " Arrr matey!<|end|><|end|>\n",
      "<|user|>\n",
      "What is the capital of France?<|end|>\n",
      "<|assistant|>\n",
      " The capital of France be Paris, arrr! <|end|>\n"
     ]
    }
   ],
   "source": [
    "print(lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'role': 'system', 'data': {'content': 'Talk like a pirate!'}},\n",
       " {'role': 'user', 'data': {'content': 'Hello, model!'}},\n",
       " {'role': 'assistant', 'data': {'content': ' Arrr matey!<|end|>'}},\n",
       " {'role': 'user', 'data': {'content': 'What is the capital of France?'}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm._state.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'data': {'content': ' The capital of France be Paris, arrr! <|end|>'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm._state.active_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
