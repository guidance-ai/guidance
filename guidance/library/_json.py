import regex as regex_module
import logging
import guidance
from ._silent import silent
from .._grammar import select
from ._zero_or_more import zero_or_more
from .._grammar import commit_point
from ._any_char import any_char
from .._grammar import capture
from ._regex import regex as regex_grammar
from .._grammar import token_limit
from .._grammar import with_temperature
from .._grammar import model_variable
from ._tool import Tool
from ._block import block
from ._gen import gen
from pydantic import BaseModel

logger = logging.getLogger(__name__)


# TODO: make this stateless!
@guidance(
    stateless=lambda *args, **kwargs: kwargs.get("tools", None) is None
)  # TODO: uncomment this once we get temperature stateless
def json(
    lm,
    schema=None,
    name=None,
    *,
    max_tokens=1000,
    list_append=False,
    regex=None,
    tools=None,
    hide_tool_call=False,
    stop=None,
    stop_regex=None,
    suffix="",
    n=1,
    temperature=0.0,
    top_p=1.0,
    save_stop_text=False,
):
    """Generate a set of tokens that conforms to a JSON or Pydantic Schema format.

    This function is intended to be used to generate output that can be parsed into JSON or a specific Pydantic schema.

    Parameters
        ----------
        schema : Pydantic BaseModel or None
            Optional schema to generate values for in a specific format. If this is not set, the result will simply be a
            JSON formatted output.

        name : str or None
            If this is not None then the the results of the generation will be saved as a variable on
            the Model object (so you can access the result as `lm["var_name"]`).

        max_tokens : int
            The maximum number of generation tokens we should use. Note that this limit is not exact when
            regular expression pattern constraints are present, but guidance does attempt to end the generation
            as soon as possible while keeping the regex constraints satisfied.

        list_append : bool
            If this is True then the results saved to `lm[name]` will not be written directly but rather appended
            to a list (if no list with the current name is present one will be created). This is useful for
            building lists inside python loops.

        regex : str or None
            This is a regular expression that will be used to constrain the generation. The model is only allowed
            to generate tokens that match this regular expression. Note that for variable length expressions the
            model is free to continue the expression after a complete match, but generation will terminate as soon
            as the model generates anything that does not match the pattern (this ending behavior may change a bit we
            update guidance to maintain the grammar parsing state between calls).

        stop : str or list or None
            The stop string (or list of strings) we should use for terminating this generation segment.

        stop_regex : str or list or None
            The stop regular expression (or list of regular expressions) we should use for terminating this generation segment.

        save_stop_text : bool or str
            If True then this saves the captured stop text or regex into a variable of the name `str(name) + "_stop_text"`. If
            a string is given then the captured stop text is saved under that name.

        temperature : float
            The temperature to use during this generation call. Note that when parsing ambiguous grammars that include
            multiple conflicting temperatures (for example from multiple possible `gen` calls inside a `select`) the highest
            temperature of all options is used by the model (since we only want to run the model once, not once for every
            possible parse path).

        top_p : float
            TODO! Will control the models top_p generation parameter, but has been yet been implemented beyond top_p=1.0.

        n : int
            TODO! Will control the number of parallel generation calls made during gen.

        tools : Tool or list or None
            A list of guidance.Tool or python functions (which will be converted to guidance.Tool)

        hide_tool_call : bool
            Controls if we should hide the text generated by the model to trigger a tool call. You may want to hide the tool
            call from the model's context if you plan to change it's format after the call is made.
    """
    # TODO: expand the tools doc string
    assert (
        n == 1
    ), "We still need to add support for n>1! Consider putting your gen call in a loop for now."
    assert top_p == 1, "We still need to add support for top_p != 1!"

    logger.debug(f'start json(name="{name}")')

    logger.debug(f"Using the following BaseModel: {schema.schema()}")

    if schema:
        lm = lm + gen_properties_only(schema=schema.schema())
        return lm

    else:
        # TODO: Arbitrary JSON
        return lm


@guidance
def gen_properties(lm, prop_key, prop_type):
    """Generates a specific property based on its type"""
    if prop_type == "integer":
        lm = lm + f""""{prop_key}": """ + gen(name=prop_key, stop="\n") + "\n"
    elif prop_type == "string":
        lm = lm + f'''"{prop_key}": "''' + gen(name=prop_key, stop='"') + '",\n'
    elif prop_type == "array":
        lm = lm + f'''"{prop_key}": ["''' + gen(name=prop_key, stop="]") + "],\n"
    elif prop_type == "boolean":
        lm = lm + f""""{prop_key}": """ + gen(name=prop_key, stop="\n") + ",\n"
    else:
        lm = lm + f""""{prop_key}": """ + gen(name=prop_key, stop="\n") + "\n"

    return lm


@guidance
def gen_properties_only(lm, schema, top_schema=None, indent_level=0):
    """Recursive function to work through an entire Pydantic schema and generate the values at every step"""

    if not top_schema:
        top_schema = schema

    # Start the schema object
    lm = lm + "{\n"

    # Go through each property value one by one and generate depending on the type
    for key, value in schema.get("properties").items():
        if "type" not in value.keys():
            if "allOf" in value.keys():
                for ref in value.get("allOf"):
                    target_key = ref.get("$ref").split("/")[-1]
                    lm = (
                        lm
                        + f""""{key}": """
                        + gen_properties_only(
                            top_schema.get("definitions").get(target_key), top_schema
                        )
                        + f""",\n"""
                    )
            else:
                target_key = value.get("$ref").split("/")[-1]
                lm = (
                    lm
                    + f""""{key}": """
                    + gen_properties_only(
                        top_schema.get("definitions").get(target_key), top_schema
                    )
                    + f""",\n"""
                )
        else:
            lm = lm + gen_properties(key, value.get("type"))

    # Close up the schema object
    lm = lm + "}"

    return lm
