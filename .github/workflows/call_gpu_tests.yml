name: call_gpu_tests

on:
  workflow_call:
    inputs:
      os:
        required: true
        type: string
      python-version:
        required: true
        type: string
      model:
        required: true
        type: string
    secrets:
      HF_TOKEN:
        required: false
  workflow_dispatch:
    inputs:
      os:
        required: false
        type: string
        default: "gpu-runner"
      python-version:
        required: false
        type: string
        default: "3.12"
      model:
        required: false
        type: string
        default: "llamacpp_llama2_7b_gpu" # also try "transformers_gpt2_gpu", "transformers_phi2_gpu", etc
      commit_id:
        description: 'Branch or Commit ID (optional)'
        required: false
        type: string

jobs:
  gpu_tests:
    runs-on: ${{ inputs.os }}
    steps:
      - name: Checkout repo at ${{ github.event_name == 'workflow_dispatch' && inputs.commit_id || github.sha }}
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event_name == 'workflow_dispatch' && inputs.commit_id || github.sha }}
      - name: Set up Python ${{ inputs.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ inputs.python-version }}
      - name: Install Rust
        shell: bash
        run: |
           curl https://sh.rustup.rs -sSf | sh -s -- -y --default-toolchain 1.75.0
           echo "$HOME/.cargo/bin" >> $GITHUB_PATH
      - name: Install NVIDIA SDK
        shell: bash
        run: |
          nvidia-smi
          sudo apt-get --yes update
          sudo apt-get --yes install cuda-toolkit-12.6
          echo "/usr/local/cuda-12.6/bin" >> $GITHUB_PATH
      - name: Install guidance in ${{ inputs.os }}
        shell: bash
        run: |
          pip install --upgrade pip
          pip install sentencepiece accelerate
          CMAKE_ARGS="-DGGML_CUDA=on" pip install -e .[llamacpp,transformers,test]
      - name: Check GPU available
        shell: bash
        run: |
          python -c "import torch; assert torch.cuda.is_available()"
      - name: gpu_tests for ${{ inputs.model }}
        shell: bash
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          pytest -vv --cov=guidance --cov-report=xml --cov-report=term-missing \
            --selected_model ${{ inputs.model }} \
            ./tests/model_integration ./tests/model_specific
      - name: Upload coverage reports to Codecov
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
